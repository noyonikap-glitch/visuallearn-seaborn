# VisualLearn

A lightweight, intuitive tool for **visualizing how machine learning models learn â€” in real time.**  
Perfect for **education**, **debugging**, **content creation**, or just understanding the magic under the hood.

---

## âœ¨ What It Does

- âœ… Visualizes **decision boundaries** as they evolve
- ğŸ“‰ Plots **loss curves** in real time
- ğŸ”¬ Tracks **activation distributions** per layer
- ğŸ” Shows **gradient histograms** during backpropagation
- ğŸï¸ Exports training as **GIF or MP4**

---

## ğŸ“¦ Currently Supports

- ğŸ§  **PyTorch** (MLPs with `nn.Linear`, `nn.ReLU`)
- ğŸ”¢ **scikit-learn** classifiers with `.fit()` and `.predict()`
- ğŸ“ 2D input datasets (e.g., `make_moons`, `make_circles`)
- ğŸ†š Side-by-side comparison of **multiple models** learning the same dataset
- ğŸ¨ Manual or modular plotting (works with any `matplotlib` figure or axes)

---

## ğŸš€ Future Plans

- ğŸ–¼ï¸ Visualizing **CNN feature maps** and filters
- ğŸ”— Support for **Transformers, RNNs, and custom activations**
- ğŸ§± Visualizing **weight updates** and **dead neurons**
- ğŸ“ Integration with **experiment tracking** tools (e.g., Weights & Biases, TensorBoard)
- ğŸ¯ CLI and web export (`mlvis run demo --gif`)

---

## ğŸ“ Use Cases

- ğŸ« Teaching machine learning concepts visually
- ğŸ“Š Debugging model behavior, layer by layer
- ğŸï¸ Creating demos for presentations, lectures, or social media
- ğŸ§ª Comparing architectures (e.g., shallow vs deep MLPs)
- ğŸ”¬ Observing **gradient flow**, **activation saturation**, and more

---

## ğŸ› ï¸ Installation

### Basic Installation
```bash
pip install visuallearn
```

### With Optional Dependencies
```bash
# For PyTorch support
pip install visuallearn[pytorch]

# For video export (MP4)
pip install visuallearn[video]

# For development
pip install visuallearn[dev]

# Everything included
pip install visuallearn[all]
```

### From Source
```bash
git clone https://github.com/noyonikap-glitch/visuallearn.git
cd visuallearn
pip install -e .
```

## ğŸš€ Quick Start

```python
import visuallearn as vl
from sklearn.datasets import make_moons
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

# Generate data
X, y = make_moons(n_samples=300, noise=0.3, random_state=42)
X = StandardScaler().fit_transform(X)

# Train model
model = SVC(kernel='rbf', probability=True)
model.fit(X, y)

# Visualize decision boundary
import matplotlib.pyplot as plt
fig, ax = plt.subplots(figsize=(8, 6))
vl.plot_decision_boundary(model, X, y, ax)
plt.show()
```

### PyTorch Real-time Training Visualization

```python
import torch
import torch.nn as nn
import visuallearn as vl

# Your PyTorch model
model = nn.Sequential(
    nn.Linear(2, 16), nn.ReLU(),
    nn.Linear(16, 8), nn.ReLU(), 
    nn.Linear(8, 2)
)

# Set up tracking
activation_tracker = vl.ActivationTracker()
activation_tracker.attach_hooks(model)

# Create visualizer
visualizer = vl.CombinedPlotCoordinator(X, y, activation_tracker=activation_tracker)
visualizer.enable_recording()

# Training loop with live updates
for epoch in range(100):
    # ... your training code ...
    visualizer.update(model, epoch, loss_value)

# Export as GIF
visualizer.export("training.gif", format="gif")
```

